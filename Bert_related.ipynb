{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "F9NYiE4K51o-",
    "outputId": "1bde2941-a2c3-4179-a6fd-274d7c47f2a9"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.clear_all_output();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.clear_all_output();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HAssmxxJp0yM"
   },
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "hsZvic2YxnTz",
    "outputId": "510c26ea-e632-4356-a8a2-da72f07a462c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version :  1.15.3\n",
      "tensorflow_hub version :  0.8.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"tensorflow version : \", tf.__version__)\n",
    "print(\"tensorflow_hub version : \", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "hhbGEfwgdEtw",
    "outputId": "e68d73a8-b81a-4573-da97-592569ba3ec1"
   },
   "outputs": [],
   "source": [
    "#Importing BERT modules\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyzTzLpyqJUf"
   },
   "source": [
    "## Setting The Output Directory\n",
    "\n",
    "While fine-tuning the model, we will save the training checkpoints and the model in an output directory so that we can use the trained model for our predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "US_EAnICvP7f",
    "outputId": "e5327bdf-ac9a-4a9a-97df-643d1e9c9519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: model_pooled_concat_sequence_related_2_layer_ms4 *****\n"
     ]
    }
   ],
   "source": [
    "# Set the output directory for saving model file\n",
    "OUTPUT_DIR = 'model_pooled_concat_sequence_related_2_layer_ms4'\n",
    "\n",
    "#@markdown Whether or not to clear/delete the directory and create a new one\n",
    "DO_DELETE = False #@param {type:\"boolean\"}\n",
    "\n",
    "if DO_DELETE:\n",
    "  try:\n",
    "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmFYvkylMwXn"
   },
   "source": [
    "## Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock='AAPL'\n",
    "year='2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>search_term</th>\n",
       "      <th>label0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft beat on revenue expectations, driven...</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tesla and Microsoft topped Wall Street earning...</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Microsoft pledges to completely remove carbon ...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Microsoft ex-employee says contractors in Chin...</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10055</th>\n",
       "      <td>Marvel delays Doctor Strange and Thor sequels ...</td>\n",
       "      <td>Sony</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>Sony told to pay BBC £5m for stock damaged in ...</td>\n",
       "      <td>Sony</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>Sony invests $400 million in Chinese video sit...</td>\n",
       "      <td>Sony</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10065</th>\n",
       "      <td>Roku shares climb 10% on strong growth in stre...</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10071</th>\n",
       "      <td>Roku launches ad-funded streaming channel in '...</td>\n",
       "      <td>ROKU</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5237 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text search_term  label0\n",
       "2      The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...        MSFT       1\n",
       "3      Microsoft beat on revenue expectations, driven...        MSFT       1\n",
       "4      Tesla and Microsoft topped Wall Street earning...        MSFT       1\n",
       "6      Microsoft pledges to completely remove carbon ...   Microsoft       1\n",
       "11     Microsoft ex-employee says contractors in Chin...   Microsoft       1\n",
       "...                                                  ...         ...     ...\n",
       "10055  Marvel delays Doctor Strange and Thor sequels ...        Sony       1\n",
       "10061  Sony told to pay BBC £5m for stock damaged in ...        Sony       1\n",
       "10062  Sony invests $400 million in Chinese video sit...        Sony       1\n",
       "10065  Roku shares climb 10% on strong growth in stre...        ROKU       1\n",
       "10071  Roku launches ad-funded streaming channel in '...        ROKU       1\n",
       "\n",
       "[5237 rows x 3 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('model1_data_related.csv',index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4380\n",
       "0     857\n",
       "Name: label0, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label0'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag=data['label0']\n",
    "data_feature=data\n",
    "data_feature.drop('label0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>search_term</th>\n",
       "      <th>label0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Dow hit 29,000 today. $AAPL, $GS, $UNH, $N...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One stealth technical indicator could be key t...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And there it is. $AAPL is green</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$AAPL back above $300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>Top-rated companies including ­Disney, Apple a...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>Just to put things into perspective: FANGMAN (...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>Buy Boeing and Apple and enjoy the show.</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>BEIJING IS READY TO TAKE COUNTERMEASURES AGAIN...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>Here's why my job is tough: I have liked Apple...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2039 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text search_term label0\n",
       "0     The Dow hit 29,000 today. $AAPL, $GS, $UNH, $N...        AAPL     14\n",
       "1     The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...        AAPL     55\n",
       "2     One stealth technical indicator could be key t...        AAPL      6\n",
       "3                      And there it is. $AAPL is green         AAPL      2\n",
       "4                                 $AAPL back above $300        AAPL      2\n",
       "...                                                 ...         ...    ...\n",
       "2042  Top-rated companies including ­Disney, Apple a...       Apple    143\n",
       "2043  Just to put things into perspective: FANGMAN (...       Apple    818\n",
       "2044          Buy Boeing and Apple and enjoy the show.        Apple      1\n",
       "2045  BEIJING IS READY TO TAKE COUNTERMEASURES AGAIN...       Apple    150\n",
       "2046  Here's why my job is tough: I have liked Apple...       Apple     44\n",
       "\n",
       "[2039 rows x 3 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind=[]\n",
    "data_pred=pd.read_csv(stock+'_stock_sum/'+stock+'_stock_news_'+year+'.csv')\n",
    "data_pred_time=data_pred.iloc[:,[2,-1,3,5]]\n",
    "data_pred=data_pred.iloc[:,[2,-1,3]]\n",
    "\n",
    "data_pred.columns=['text','search_term','label0']\n",
    "data_pred.drop(index=(data_pred[data_pred.text=='text'].index),inplace=True)\n",
    "data_pred_time.drop(index=(data_pred_time[data_pred_time.text=='text'].index),inplace=True)\n",
    "data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=[]\n",
    "for i in range(len(data_pred)):\n",
    "    index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred_time.index=index\n",
    "data_pred_time.to_csv(stock+'_stock_sum/'+stock+'tweets_include_time'+year+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>search_term</th>\n",
       "      <th>label0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Dow hit 29,000 today. $AAPL, $GS, $UNH, $N...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One stealth technical indicator could be key t...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And there it is. $AAPL is green</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$AAPL back above $300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>Top-rated companies including ­Disney, Apple a...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>Just to put things into perspective: FANGMAN (...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>Buy Boeing and Apple and enjoy the show.</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>BEIJING IS READY TO TAKE COUNTERMEASURES AGAIN...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>Here's why my job is tough: I have liked Apple...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2039 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text search_term label0\n",
       "0     The Dow hit 29,000 today. $AAPL, $GS, $UNH, $N...        AAPL      0\n",
       "1     The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...        AAPL      0\n",
       "2     One stealth technical indicator could be key t...        AAPL      0\n",
       "3                      And there it is. $AAPL is green         AAPL      0\n",
       "4                                 $AAPL back above $300        AAPL      0\n",
       "...                                                 ...         ...    ...\n",
       "2034  Top-rated companies including ­Disney, Apple a...       Apple      0\n",
       "2035  Just to put things into perspective: FANGMAN (...       Apple      0\n",
       "2036          Buy Boeing and Apple and enjoy the show.        Apple      0\n",
       "2037  BEIJING IS READY TO TAKE COUNTERMEASURES AGAIN...       Apple      0\n",
       "2038  Here's why my job is tough: I have liked Apple...       Apple      0\n",
       "\n",
       "[2039 rows x 3 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred.index=index\n",
    "for i in range(len(data_pred)):\n",
    "    data_pred.iloc[i,-1]=0\n",
    "    data_pred.iloc[i,0]=data_pred.iloc[i,0].split('http')[0]\n",
    "data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred_flag=data_pred['label0']\n",
    "data_pred_feature=data_pred\n",
    "data_pred_feature.drop('label0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset to train test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3665, 2)\n",
      "(1572, 2)\n",
      "(3665,)\n",
      "(1572,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_val, y_train, y_test_val=train_test_split(data_feature,data_flag,test_size=0.3,random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1053, 2)\n",
      "(519, 2)\n",
      "(1053,)\n",
      "(519,)\n"
     ]
    }
   ],
   "source": [
    "X_test, X_val, y_test, y_val=train_test_split(X_test_val,y_test_val,test_size=0.33,random_state=42)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3665, 2)\n",
      "(3665,)\n",
      "(1053, 2)\n",
      "(1053,)\n",
      "(519, 2)\n",
      "(519,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred=data_pred_feature\n",
    "y_pred=data_pred_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3073\n",
       "0     592\n",
       "Name: label0, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3665"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_term=list(X_train['search_term'])\n",
    "len(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>search_term</th>\n",
       "      <th>label0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9601</th>\n",
       "      <td>‘What the f*** is the matter with you?’: Welsh...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>New for subscribers: Analysts see stocks like ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>Apple planning 'major 5G iPhone redesign' for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>A man who was awaiting results on a coronaviru...</td>\n",
       "      <td>1</td>\n",
       "      <td>JetBlue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>As governments race to roll out pandemic-fight...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>GM employee at Cole Engineering Center tests p...</td>\n",
       "      <td>1</td>\n",
       "      <td>GM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316</th>\n",
       "      <td>France urges Apple and Google to ease privacy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>Two black men in coronavirus face masks follow...</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10046</th>\n",
       "      <td>Public health officials in Aurora, Colorado, o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>U.S. electric carmaker Tesla started deliverin...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3665 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  search_term   label0\n",
       "9601   ‘What the f*** is the matter with you?’: Welsh...            0     Zoom\n",
       "8600   New for subscribers: Analysts see stocks like ...            1   Amazon\n",
       "7302   Apple planning 'major 5G iPhone redesign' for ...            1    Apple\n",
       "5587   A man who was awaiting results on a coronaviru...            1  JetBlue\n",
       "7353   As governments race to roll out pandemic-fight...            1    Apple\n",
       "...                                                  ...          ...      ...\n",
       "6057   GM employee at Cole Engineering Center tests p...            1       GM\n",
       "7316   France urges Apple and Google to ease privacy ...            1    Apple\n",
       "9988   Two black men in coronavirus face masks follow...            1  Walmart\n",
       "10046  Public health officials in Aurora, Colorado, o...            1  Walmart\n",
       "1787   U.S. electric carmaker Tesla started deliverin...            1    Tesla\n",
       "\n",
       "[3665 rows x 3 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['label0']=X_train['search_term']\n",
    "X_train['search_term']=y_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3073\n",
       "0     592\n",
       "Name: search_term, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['search_term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X_test['label0']=X_test['search_term']\n",
    "X_test['search_term']=y_test\n",
    "X_val['label0']=X_val['search_term']\n",
    "X_val['search_term']=y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred['label0']=X_pred['search_term']\n",
    "X_pred['search_term']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=X_train\n",
    "val=X_val\n",
    "test=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns=['clean tweet','target','search_term']\n",
    "val.columns=['clean tweet','target','search_term']\n",
    "test.columns=['clean tweet','target','search_term']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.columns=['clean tweet','target','search_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9601</th>\n",
       "      <td>‘What the f*** is the matter with you?’: Welsh...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>New for subscribers: Analysts see stocks like ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>Apple planning 'major 5G iPhone redesign' for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>A man who was awaiting results on a coronaviru...</td>\n",
       "      <td>1</td>\n",
       "      <td>JetBlue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>As governments race to roll out pandemic-fight...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>GM employee at Cole Engineering Center tests p...</td>\n",
       "      <td>1</td>\n",
       "      <td>GM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316</th>\n",
       "      <td>France urges Apple and Google to ease privacy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>Two black men in coronavirus face masks follow...</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10046</th>\n",
       "      <td>Public health officials in Aurora, Colorado, o...</td>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>U.S. electric carmaker Tesla started deliverin...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3665 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean tweet  target search_term\n",
       "9601   ‘What the f*** is the matter with you?’: Welsh...       0        Zoom\n",
       "8600   New for subscribers: Analysts see stocks like ...       1      Amazon\n",
       "7302   Apple planning 'major 5G iPhone redesign' for ...       1       Apple\n",
       "5587   A man who was awaiting results on a coronaviru...       1     JetBlue\n",
       "7353   As governments race to roll out pandemic-fight...       1       Apple\n",
       "...                                                  ...     ...         ...\n",
       "6057   GM employee at Cole Engineering Center tests p...       1          GM\n",
       "7316   France urges Apple and Google to ease privacy ...       1       Apple\n",
       "9988   Two black men in coronavirus face masks follow...       1     Walmart\n",
       "10046  Public health officials in Aurora, Colorado, o...       1     Walmart\n",
       "1787   U.S. electric carmaker Tesla started deliverin...       1       Tesla\n",
       "\n",
       "[3665 rows x 3 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3073\n",
       "0     592\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3073"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value=0\n",
    "for i in train['target'].value_counts():\n",
    "    if i>max_value:\n",
    "        max_value=i\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([9601, 3287, 3517, 7428, 6366, 5396, 5303, 8907, 3751, 5160,\n",
       "            ...\n",
       "            9443, 3991, 1631,  501, 5631,  420, 5393, 4150, 5055, 6669],\n",
       "           dtype='int64', length=592)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0_down=train[train['target']==0].index\n",
    "train_0_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 8600,  7302,  5587,  7353,  9201,  9939,  6149,  4192,  8478,\n",
       "             5336,\n",
       "            ...\n",
       "              311,  5686,  6195,  8546,   930,  6057,  7316,  9988, 10046,\n",
       "             1787],\n",
       "           dtype='int64', length=3073)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1_down=train[train['target']==1].index\n",
    "train_1_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=list(train_0_down)+list(train_0_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "if (max_value-len(train_0_down))<=len(train_0_down):\n",
    "    slice1 = random.sample(list(train_0_down), max_value-len(train_0_down))\n",
    "else:\n",
    "    num=int(max_value/len(train_0_down))\n",
    "    train2=list(train_0_down)\n",
    "    for i in range(num):\n",
    "        train2=train2+list(train_0_down)\n",
    "    slice1 = random.sample(train2, max_value-len(train_0_down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (max_value-len(train_1_down))<=len(train_1_down):\n",
    "    slice2 = random.sample(list(train_1_down), max_value-len(train_1_down))\n",
    "else:\n",
    "    num=int(max_value/len(train_1_down))\n",
    "    train3=list(train_1_down)\n",
    "    for i in range(num):\n",
    "        train3=train3+list(train_1_down)\n",
    "    slice2 = random.sample(train3, max_value-len(train_1_down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice4=slice1+slice2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in slice4:\n",
    "    df=train[train.index==i]\n",
    "    df.index=df.index+15000\n",
    "    train=pd.concat([train,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3073\n",
       "0    3073\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "e_rukDBlbvCj",
    "outputId": "1af8146b-263e-4a79-fe5f-22b7b12e26c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape : (6146, 3)\n",
      "Validation Set Shape : (519, 3)\n",
      "Test Set Shape : (1053, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Shape :\", train.shape)\n",
    "print(\"Validation Set Shape :\", val.shape)\n",
    "print(\"Test Set Shape :\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U9IwgBb-cOm3",
    "outputId": "3fcaf40e-eb39-4b49-b8fe-867441233b87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique classes\n",
    "train['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "kToy7D-TSrn_",
    "outputId": "f94304a3-b833-42ed-a26a-bba41f939ed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c400dad50>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Distribution of classes\n",
    "train['target'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuMOGwFui4it"
   },
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'clean tweet'\n",
    "LABEL_COLUMN = 'target'\n",
    "# The list containing all the classes (train['SECTION'].unique())\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "redeal=['ZM','XOM','Walmart','Virgin Galactic','United Airlines','USO','Spirit Airlines','Southwest Airlines',\n",
    " 'SIRI','Royal Caribbean','ROKU','Pfizer','Occidental Petroleum','Norwegian Cruise Line','New Residential','Moderna','Marathon Oil',\n",
    " 'Luckin Coffee','LYFT','LUV','LK','JetBlue','JPM','Halliburton','Groupon','GoPro','Gilead Sciences','Fitbit','Exxon Mobil',\n",
    " 'Energy Transfer','Delta Air Lines','Coca-Cola','Canopy Growth','CCL','Beyond Meat','Berkshire Hathaway','Bank of America','BYND',\n",
    " 'Aurora Cannabis','American Airlines','Alibaba','AMD','DIS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9601</th>\n",
       "      <td>‘What the f*** is the matter with you?’: Welsh...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>New for subscribers: Analysts see stocks like ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>Apple planning 'major 5G iPhone redesign' for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>a man who was awaiting results on a coronaviru...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>As governments race to roll out pandemic-fight...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22964</th>\n",
       "      <td>Chinese state media is flooding Facebook and I...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22968</th>\n",
       "      <td>Family members posted several tributes to Pete...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19306</th>\n",
       "      <td>Nessun paese è stato colpito dal coronavirus c...</td>\n",
       "      <td>0</td>\n",
       "      <td>DAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20612</th>\n",
       "      <td>YouTube and Amazon Prime join Netflix by reduc...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17269</th>\n",
       "      <td>China is restricting travel of 30 million peop...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6146 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean tweet  target   search_term\n",
       "9601   ‘What the f*** is the matter with you?’: Welsh...       0          Zoom\n",
       "8600   New for subscribers: Analysts see stocks like ...       1        Amazon\n",
       "7302   Apple planning 'major 5G iPhone redesign' for ...       1         Apple\n",
       "5587   a man who was awaiting results on a coronaviru...       1  presentation\n",
       "7353   As governments race to roll out pandemic-fight...       1         Apple\n",
       "...                                                  ...     ...           ...\n",
       "22964  Chinese state media is flooding Facebook and I...       0      Facebook\n",
       "22968  Family members posted several tributes to Pete...       0      Facebook\n",
       "19306  Nessun paese è stato colpito dal coronavirus c...       0           DAL\n",
       "20612  YouTube and Amazon Prime join Netflix by reduc...       0        Amazon\n",
       "17269  China is restricting travel of 30 million peop...       0      Facebook\n",
       "\n",
       "[6146 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(train)):\n",
    "    if train.iloc[i,2] in redeal:\n",
    "        cleaning=train.iloc[i,0].lower()\n",
    "        cleaning2=train.iloc[i,2].lower()\n",
    "        tweets=cleaning.replace(cleaning2,'presentation')\n",
    "        train.iloc[i,0]=tweets\n",
    "        train.iloc[i,2]='presentation'\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>#BREAKING: Ukrainian Prime Minister Oleksiy Ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>Amazon slated to report fourth-quarter earning...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10051</th>\n",
       "      <td>two workers at a chicago-area presentation sto...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>Missouri city offers $1 billion in incentives ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902</th>\n",
       "      <td>Ford's three-part unsecured debt offering wort...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>“the objective is not no plastics, it’s zero w...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8701</th>\n",
       "      <td>Amazon said it was investigating claims of 'su...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>Boeing 737 crash in Tehran kills 176</td>\n",
       "      <td>1</td>\n",
       "      <td>Boeing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Facebook apologises for offensive translation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>Ryanair passengers nervous about travelling on...</td>\n",
       "      <td>1</td>\n",
       "      <td>Boeing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean tweet  target   search_term\n",
       "2144   #BREAKING: Ukrainian Prime Minister Oleksiy Ho...       0      Facebook\n",
       "2478   Amazon slated to report fourth-quarter earning...       1        Amazon\n",
       "10051  two workers at a chicago-area presentation sto...       1  presentation\n",
       "7852   Missouri city offers $1 billion in incentives ...       1         Tesla\n",
       "6902   Ford's three-part unsecured debt offering wort...       1          Ford\n",
       "...                                                  ...     ...           ...\n",
       "2418   “the objective is not no plastics, it’s zero w...       1  presentation\n",
       "8701   Amazon said it was investigating claims of 'su...       1        Amazon\n",
       "1136                Boeing 737 crash in Tehran kills 176       1        Boeing\n",
       "2108   Facebook apologises for offensive translation ...       1      Facebook\n",
       "4686   Ryanair passengers nervous about travelling on...       1        Boeing\n",
       "\n",
       "[519 rows x 3 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(val)):\n",
    "    if val.iloc[i,2] in redeal:\n",
    "        cleaning=val.iloc[i,0].lower()\n",
    "        cleaning2=val.iloc[i,2].lower()\n",
    "        tweets=cleaning.replace(cleaning2,'presentation')\n",
    "        val.iloc[i,0]=tweets\n",
    "        val.iloc[i,2]='presentation'\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>Which companies are benefiting most from the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465</th>\n",
       "      <td>“i do think there’s such a pent-up demand for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>Facebook stops advertisers from being able to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>For the second time in the United States, a ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>PENN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>Carnival cancels cruises amid coronavirus outb...</td>\n",
       "      <td>1</td>\n",
       "      <td>Carnival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>Newspaper shocks readers by publishing full na...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8284</th>\n",
       "      <td>Zoom hires former Facebook security chief to b...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>Elon Musk’s contrarian streak built Tesla. Was...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6743</th>\n",
       "      <td>some 35,000 elderly mexicans, most between 60 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>LISTEN to our conversation with Microsoft co-f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1053 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean tweet  target   search_term\n",
       "5870  Which companies are benefiting most from the c...       1        Amazon\n",
       "8465  “i do think there’s such a pent-up demand for ...       1  presentation\n",
       "7988  Facebook stops advertisers from being able to ...       1      Facebook\n",
       "3296  For the second time in the United States, a ba...       0          PENN\n",
       "4324  Carnival cancels cruises amid coronavirus outb...       1      Carnival\n",
       "...                                                 ...     ...           ...\n",
       "5154  Newspaper shocks readers by publishing full na...       0      Facebook\n",
       "8284  Zoom hires former Facebook security chief to b...       1      Facebook\n",
       "5059  Elon Musk’s contrarian streak built Tesla. Was...       1         Tesla\n",
       "6743  some 35,000 elderly mexicans, most between 60 ...       1  presentation\n",
       "6805  LISTEN to our conversation with Microsoft co-f...       1     Microsoft\n",
       "\n",
       "[1053 rows x 3 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    if test.iloc[i,2] in redeal:\n",
    "        cleaning=test.iloc[i,0].lower()\n",
    "        cleaning2=test.iloc[i,2].lower()\n",
    "        tweets=cleaning.replace(cleaning2,'presentation')\n",
    "        test.iloc[i,0]=tweets\n",
    "        test.iloc[i,2]='presentation'\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Dow hit 29,000 today. $AAPL, $GS, $UNH, $N...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One stealth technical indicator could be key t...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And there it is. $AAPL is green</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$AAPL back above $300</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>Top-rated companies including ­Disney, Apple a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>Just to put things into perspective: FANGMAN (...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>Buy Boeing and Apple and enjoy the show.</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>BEIJING IS READY TO TAKE COUNTERMEASURES AGAIN...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>Here's why my job is tough: I have liked Apple...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2039 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean tweet target search_term\n",
       "0     The Dow hit 29,000 today. $AAPL, $GS, $UNH, $N...      0        AAPL\n",
       "1     The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...      0        AAPL\n",
       "2     One stealth technical indicator could be key t...      0        AAPL\n",
       "3                      And there it is. $AAPL is green       0        AAPL\n",
       "4                                 $AAPL back above $300      0        AAPL\n",
       "...                                                 ...    ...         ...\n",
       "2034  Top-rated companies including ­Disney, Apple a...      0       Apple\n",
       "2035  Just to put things into perspective: FANGMAN (...      0       Apple\n",
       "2036          Buy Boeing and Apple and enjoy the show.       0       Apple\n",
       "2037  BEIJING IS READY TO TAKE COUNTERMEASURES AGAIN...      0       Apple\n",
       "2038  Here's why my job is tough: I have liked Apple...      0       Apple\n",
       "\n",
       "[2039 rows x 3 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(pred)):\n",
    "    if pred.iloc[i,2] in redeal:\n",
    "        cleaning=test.iloc[i,0].lower()\n",
    "        cleaning2=test.iloc[i,2].lower()\n",
    "        tweets=cleaning.replace(cleaning2,'presentation')\n",
    "        pred.iloc[i,0]=tweets\n",
    "        pred.iloc[i,2]='presentation'\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V399W0rqNJ-Z"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "BERT model accept only a specific type of input and the datasets are usually structured to have the following four features:\n",
    "\n",
    "* guid : A unique id that represents an observation.\n",
    "* text_a : The text we need to classify into given categories\n",
    "* text_b: It is used when we're training a model to understand the relationship between sentences and it does not apply for classification problems.\n",
    "* label: It consists of the labels or classes or categories that a given text belongs to.\n",
    " \n",
    "In our dataset we have text_a and label. The following code block will create objects for each of the above mentioned features for all the records in our dataset using the InputExample class provided in the BERT library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9gEt5SmM6i6"
   },
   "outputs": [],
   "source": [
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_InputExamples = pred.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "a7UC2dnVRsoZ",
    "outputId": "d081cbf9-b9d1-468e-a163-cae3e8ab7f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Row 0 - guid of training set :  None\n",
      "\n",
      "### Row 0 - text_a of training set : \n",
      " ‘What the f*** is the matter with you?’: Welsh health minister swears about colleague while unmuted during Zoom cabinet meeting \n",
      "\n",
      "### Row 0 - text_b of training set :  None\n",
      "\n",
      "### Row 0 - label of training set :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"### Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
    "print(\"\\n### Row 0 - text_a of training set : \\n\", train_InputExamples.iloc[0].text_a)\n",
    "print(\"\\n### Row 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
    "print(\"\\n### Row 0 - label of training set : \", train_InputExamples.iloc[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSHZiuLt51p6"
   },
   "source": [
    "## Tokenizing Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMWiDtpyQSoU"
   },
   "source": [
    "We will now get down to business with the pretrained BERT.  In this example we will use the ```bert_uncased_L-12_H-768_A-12/1``` model. To check all available versions click [here](https://tfhub.dev/s?network-architecture=transformer&publisher=google).\n",
    "\n",
    "We will be using the vocab.txt file in the model to map the words in the dataset to indexes. Also the loaded BERT model is trained on uncased/lowercase data and hence the data we feed to train the model should also be of lowercase.\n",
    "\n",
    "---\n",
    "\n",
    "The following code block loads the pre-trained BERT model and initializers a tokenizer object for tokenizing the texts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "IhJSe0QHNG7U",
    "outputId": "56281e6a-c7d8-4692-b7c9-b0313a863267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "        \n",
    "    # !!! this is time-consuming as the model is giant !!!\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB) # second time is fast as the module is cached\n",
    "    \n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all', 'bed', 'boeing', 'ap', '##mas', '##k', '##for', 'airline']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"all bed Boeing apmaskfor airline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "t3T3jSpjSxmd",
    "outputId": "57a44561-de5d-45a4-8be8-fd824313cff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‘', 'what', 'the', 'f', '*', '*', '*', 'is', 'the', 'matter', 'with', 'you', '?', '’', ':', 'welsh', 'health', 'minister', 'swear', '##s', 'about', 'colleague', 'while', 'un', '##mute', '##d', 'during', 'zoom', 'cabinet', 'meeting']\n"
     ]
    }
   ],
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9601</th>\n",
       "      <td>‘What the f*** is the matter with you?’: Welsh...</td>\n",
       "      <td>0</td>\n",
       "      <td>Zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8600</th>\n",
       "      <td>New for subscribers: Analysts see stocks like ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>Apple planning 'major 5G iPhone redesign' for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>a man who was awaiting results on a coronaviru...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>As governments race to roll out pandemic-fight...</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22964</th>\n",
       "      <td>Chinese state media is flooding Facebook and I...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22968</th>\n",
       "      <td>Family members posted several tributes to Pete...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19306</th>\n",
       "      <td>Nessun paese è stato colpito dal coronavirus c...</td>\n",
       "      <td>0</td>\n",
       "      <td>DAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20612</th>\n",
       "      <td>YouTube and Amazon Prime join Netflix by reduc...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17269</th>\n",
       "      <td>China is restricting travel of 30 million peop...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6146 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean tweet  target   search_term\n",
       "9601   ‘What the f*** is the matter with you?’: Welsh...       0          Zoom\n",
       "8600   New for subscribers: Analysts see stocks like ...       1        Amazon\n",
       "7302   Apple planning 'major 5G iPhone redesign' for ...       1         Apple\n",
       "5587   a man who was awaiting results on a coronaviru...       1  presentation\n",
       "7353   As governments race to roll out pandemic-fight...       1         Apple\n",
       "...                                                  ...     ...           ...\n",
       "22964  Chinese state media is flooding Facebook and I...       0      Facebook\n",
       "22968  Family members posted several tributes to Pete...       0      Facebook\n",
       "19306  Nessun paese è stato colpito dal coronavirus c...       0           DAL\n",
       "20612  YouTube and Amazon Prime join Netflix by reduc...       0        Amazon\n",
       "17269  China is restricting travel of 30 million peop...       0      Facebook\n",
       "\n",
       "[6146 rows x 3 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part=train\n",
    "train_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>#BREAKING: Ukrainian Prime Minister Oleksiy Ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>Amazon slated to report fourth-quarter earning...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10051</th>\n",
       "      <td>two workers at a chicago-area presentation sto...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>Missouri city offers $1 billion in incentives ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902</th>\n",
       "      <td>Ford's three-part unsecured debt offering wort...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>“the objective is not no plastics, it’s zero w...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8701</th>\n",
       "      <td>Amazon said it was investigating claims of 'su...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>Boeing 737 crash in Tehran kills 176</td>\n",
       "      <td>1</td>\n",
       "      <td>Boeing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>Facebook apologises for offensive translation ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>Ryanair passengers nervous about travelling on...</td>\n",
       "      <td>1</td>\n",
       "      <td>Boeing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean tweet  target   search_term\n",
       "2144   #BREAKING: Ukrainian Prime Minister Oleksiy Ho...       0      Facebook\n",
       "2478   Amazon slated to report fourth-quarter earning...       1        Amazon\n",
       "10051  two workers at a chicago-area presentation sto...       1  presentation\n",
       "7852   Missouri city offers $1 billion in incentives ...       1         Tesla\n",
       "6902   Ford's three-part unsecured debt offering wort...       1          Ford\n",
       "...                                                  ...     ...           ...\n",
       "2418   “the objective is not no plastics, it’s zero w...       1  presentation\n",
       "8701   Amazon said it was investigating claims of 'su...       1        Amazon\n",
       "1136                Boeing 737 crash in Tehran kills 176       1        Boeing\n",
       "2108   Facebook apologises for offensive translation ...       1      Facebook\n",
       "4686   Ryanair passengers nervous about travelling on...       1        Boeing\n",
       "\n",
       "[519 rows x 3 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_part=val\n",
    "val_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>Which companies are benefiting most from the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8465</th>\n",
       "      <td>“i do think there’s such a pent-up demand for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>Facebook stops advertisers from being able to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>For the second time in the United States, a ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>PENN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>Carnival cancels cruises amid coronavirus outb...</td>\n",
       "      <td>1</td>\n",
       "      <td>Carnival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>Newspaper shocks readers by publishing full na...</td>\n",
       "      <td>0</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8284</th>\n",
       "      <td>Zoom hires former Facebook security chief to b...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>Elon Musk’s contrarian streak built Tesla. Was...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6743</th>\n",
       "      <td>some 35,000 elderly mexicans, most between 60 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>LISTEN to our conversation with Microsoft co-f...</td>\n",
       "      <td>1</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1053 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean tweet  target   search_term\n",
       "5870  Which companies are benefiting most from the c...       1        Amazon\n",
       "8465  “i do think there’s such a pent-up demand for ...       1  presentation\n",
       "7988  Facebook stops advertisers from being able to ...       1      Facebook\n",
       "3296  For the second time in the United States, a ba...       0          PENN\n",
       "4324  Carnival cancels cruises amid coronavirus outb...       1      Carnival\n",
       "...                                                 ...     ...           ...\n",
       "5154  Newspaper shocks readers by publishing full na...       0      Facebook\n",
       "8284  Zoom hires former Facebook security chief to b...       1      Facebook\n",
       "5059  Elon Musk’s contrarian streak built Tesla. Was...       1         Tesla\n",
       "6743  some 35,000 elderly mexicans, most between 60 ...       1  presentation\n",
       "6805  LISTEN to our conversation with Microsoft co-f...       1     Microsoft\n",
       "\n",
       "[1053 rows x 3 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_part=test\n",
    "test_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean tweet</th>\n",
       "      <th>target</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Dow hit 29,000 today. $AAPL, $GS, $UNH, $N...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One stealth technical indicator could be key t...</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And there it is. $AAPL is green</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$AAPL back above $300</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>Top-rated companies including ­Disney, Apple a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>Just to put things into perspective: FANGMAN (...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>Buy Boeing and Apple and enjoy the show.</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>BEIJING IS READY TO TAKE COUNTERMEASURES AGAIN...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>Here's why my job is tough: I have liked Apple...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2039 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean tweet target search_term\n",
       "0     The Dow hit 29,000 today. $AAPL, $GS, $UNH, $N...      0        AAPL\n",
       "1     The Dow just hit 29,000. $AAPL, $GS, $UNH, $NK...      0        AAPL\n",
       "2     One stealth technical indicator could be key t...      0        AAPL\n",
       "3                      And there it is. $AAPL is green       0        AAPL\n",
       "4                                 $AAPL back above $300      0        AAPL\n",
       "...                                                 ...    ...         ...\n",
       "2034  Top-rated companies including ­Disney, Apple a...      0       Apple\n",
       "2035  Just to put things into perspective: FANGMAN (...      0       Apple\n",
       "2036          Buy Boeing and Apple and enjoy the show.       0       Apple\n",
       "2037  BEIJING IS READY TO TAKE COUNTERMEASURES AGAIN...      0       Apple\n",
       "2038  Here's why my job is tough: I have liked Apple...      0       Apple\n",
       "\n",
       "[2039 rows x 3 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_part=pred\n",
    "pred_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msft': 'microsoft',\n",
       " 'ford': 'ford',\n",
       " 'ge': 'general electric',\n",
       " 'dis': 'disney',\n",
       " 'aal': 'american airlines',\n",
       " 'dal': 'delta air lines',\n",
       " 'gpro': 'gopro',\n",
       " 'ccl': 'carnival',\n",
       " 'aapl': 'apple',\n",
       " 'fitbit': 'fitbit',\n",
       " 'plug': 'plug power',\n",
       " 'bac': 'bank of america',\n",
       " 'snap': 'snap',\n",
       " 'nclh': 'norwegian cruise line',\n",
       " 'ba': 'boeing',\n",
       " 'ino': 'inovio',\n",
       " 'ual': 'united airlines',\n",
       " 'cgc': 'canopy growth',\n",
       " 'uber': 'uber',\n",
       " 'rcl': 'royal caribbean',\n",
       " 'cron': 'cronos group',\n",
       " 'amd': 'amd',\n",
       " 'twtr': 'twtr',\n",
       " 'tsla': 'tesla',\n",
       " 'grpn': 'groupon',\n",
       " 'fb': 'facebook',\n",
       " 'acb': 'aurora cannabis',\n",
       " 'sbux': 'starbucks',\n",
       " 'mro': 'marathon oil',\n",
       " 'delta': 'delta',\n",
       " 'znga': 'zynga',\n",
       " 'baba': 'alibaba',\n",
       " 'uso': 'united states oil fund',\n",
       " 'ko': 'coca-cola',\n",
       " 'apha': 'aphria',\n",
       " 'dow': 'dow',\n",
       " 'xom': 'exxon mobil',\n",
       " 'mfa': 'mfa',\n",
       " 'jblu': 'jetblue',\n",
       " 'amzn': 'amazon',\n",
       " 'luv': 'southwest airlines',\n",
       " 'nio': 'nio',\n",
       " 'mrna': 'moderna',\n",
       " 'gm': 'general motor',\n",
       " 'spirit airlines': 'spirit Airlines',\n",
       " 'mgm': 'mgm',\n",
       " 'gild': 'gilead sciences',\n",
       " 'nflx': 'netflix',\n",
       " 'nrz': 'new residential',\n",
       " 'spce': 'virgin galactic',\n",
       " 'lk': 'luckin coffee',\n",
       " 'vslr': 'vivint solar',\n",
       " 'uco': 'uco',\n",
       " 'voo': 'vanguard',\n",
       " 'penn': 'penn',\n",
       " 'amc': 'amc',\n",
       " 'tlry': 'tilray',\n",
       " 'hal': 'halliburton',\n",
       " 'nok': 'nokia',\n",
       " 'lyft': 'lyft',\n",
       " 'nvda': 'nvidia',\n",
       " 'cprx': 'catalyst pharmaceuticals',\n",
       " 'spy': 'spdr s&p 500 etf',\n",
       " 'nke': 'nike',\n",
       " 'sq': 'sq',\n",
       " 'visa': 'visa',\n",
       " 'siri': 'siri',\n",
       " 'brk.b': 'berkshire hathaway',\n",
       " 'cpe': 'callon petroleum',\n",
       " 'slack': 'slack',\n",
       " 'gush': 'gush',\n",
       " 'bynd': 'beyond meat',\n",
       " 'pfe': 'pfizer',\n",
       " 'oxy': 'occidental petroleum',\n",
       " 'kos': 'kos',\n",
       " 'mcd': 'mcdonald',\n",
       " 'energy transfer': 'energy transfer',\n",
       " 'crbp': 'corbus pharmaceuticals',\n",
       " 'sphd': 'sphd',\n",
       " 'ntdoy': 'nintendo',\n",
       " 'zm': 'zoom',\n",
       " 'jpm': 'jpm',\n",
       " 'vktx': 'viking therapeutics',\n",
       " 'ibm': 'ibm',\n",
       " 'nymt': 'nymt',\n",
       " 'intc': 'intel',\n",
       " 'wmt': 'walmart',\n",
       " 'sne': 'sony',\n",
       " 'roku': 'roku',\n",
       " 'presentation': 'presentation'}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_dict={'msft':'microsoft','ford':'ford','ge':'general electric','dis':'disney','aal':'american airlines','dal':'delta air lines',\\\n",
    "               'gpro':'gopro','ccl':'carnival','aapl':'apple','fitbit':'fitbit','plug':'plug power','bac':'bank of america',\\\n",
    "               'snap':'snap','nclh':'norwegian cruise line','ba':'boeing','ino':'inovio','ual':'united airlines','cgc':\\\n",
    "                'canopy growth','uber':'uber','rcl':'royal caribbean','cron':'cronos group','amd':'amd','twtr':'twtr','tsla':\\\n",
    "               'tesla','grpn':'groupon','fb':'facebook','acb':'aurora cannabis','sbux':'starbucks','mro':'marathon oil','delta':'delta',\\\n",
    "                'znga':'zynga','baba':'alibaba','uso':'united states oil fund','ko':'coca-cola','apha':'aphria','dow':'dow',\\\n",
    "                'xom':'exxon mobil','mfa':'mfa','jblu':'jetblue','amzn':'amazon','luv':'southwest airlines','nio':'nio','mrna':'moderna',\\\n",
    "                'gm':'general motor','spirit airlines':'spirit Airlines','mgm':'mgm','gild':'gilead sciences','nflx':'netflix','nrz':'new residential','spce':\\\n",
    "                'virgin galactic','lk':'luckin coffee','vslr':'vivint solar','uco':'uco','voo':'vanguard','penn':'penn','amc':'amc','tlry':\\\n",
    "                'tilray','hal':'halliburton','nok':'nokia','lyft':'lyft','nvda':'nvidia','cprx':'catalyst pharmaceuticals','spy':\\\n",
    "                'spdr s&p 500 etf','nke':'nike','sq':'sq','visa':'visa','siri':'siri','brk.b':'berkshire hathaway','cpe':'callon petroleum',\\\n",
    "                'slack':'slack','gush':'gush','bynd':'beyond meat','pfe':'pfizer','oxy':'occidental petroleum','kos':'kos','mcd': 'mcdonald',\\\n",
    "                'energy transfer':'energy transfer','crbp':'corbus pharmaceuticals','sphd':'sphd','ntdoy':'nintendo','zm':'zoom','jpm':'jpm',\\\n",
    "                'vktx':'viking therapeutics','ibm':'ibm','nymt':'nymt','intc':'intel','wmt':'walmart','sne':'sony','roku':'roku','presentation':'presentation'}\n",
    "search_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6146"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_InputExamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "binar=[]\n",
    "nodrop_index=[]\n",
    "errr=0\n",
    "for i in range (len(train_InputExamples)):\n",
    "    c=[]\n",
    "    for j in tokenizer.tokenize(train_InputExamples.iloc[i].text_a):\n",
    "        #print(j)\n",
    "        search_1=train_part['search_term'].iloc[i]\n",
    "        if search_1.lower() in search_dict.keys():\n",
    "            search_2=search_dict[search_1.lower()]\n",
    "        else:\n",
    "            search_2=list(search_dict.keys())[list(search_dict.values()).index(search_1.lower())]\n",
    "        if j == search_1.lower() or j == search_2:\n",
    "            c.append(1)\n",
    "        else:\n",
    "            c.append(0)\n",
    "    if search_1=='presentation':\n",
    "        train_part['search_term'].iloc[i]='[MASK]'\n",
    "        train_InputExamples.iloc[3].text_a=train_InputExamples.iloc[3].text_a.replace('presentation','[MASK]')\n",
    "    if sum(c)!=0:\n",
    "        nodrop_index.append(i)\n",
    "        binar.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples=train_InputExamples.iloc[nodrop_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5809"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_InputExamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "binar2=[]\n",
    "for i in range (len(val_InputExamples)):\n",
    "    c=[]\n",
    "    for j in tokenizer.tokenize(val_InputExamples.iloc[i].text_a):\n",
    "        search_1=val_part['search_term'].iloc[i]    \n",
    "        if search_1.lower() in search_dict.keys():\n",
    "            search_2=search_dict[search_1.lower()]\n",
    "        else:\n",
    "            search_2=list(search_dict.keys())[list(search_dict.values()).index(search_1.lower())]\n",
    "        if j==search_1.lower() or j==search_2:\n",
    "            c.append(1)\n",
    "        else:\n",
    "            c.append(0)\n",
    "    if search_1=='presentation':\n",
    "        val_part['search_term'].iloc[i]='[MASK]'\n",
    "        val_InputExamples.iloc[3].text_a=val_InputExamples.iloc[3].text_a.replace('presentation','[MASK]')\n",
    "    binar2.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/dongyingzhe/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "binar3=[]\n",
    "for i in range (len(test_InputExamples)):\n",
    "    c=[]\n",
    "    for j in tokenizer.tokenize(test_InputExamples.iloc[i].text_a):\n",
    "        search_1=test_part['search_term'].iloc[i]    \n",
    "        if search_1.lower() in search_dict.keys():\n",
    "            search_2=search_dict[search_1.lower()]\n",
    "        else:\n",
    "            search_2=list(search_dict.keys())[list(search_dict.values()).index(search_1.lower())]\n",
    "        if j==search_1.lower() or j==search_2:\n",
    "            c.append(1)\n",
    "        else:\n",
    "            c.append(0)\n",
    "    if search_1=='presentation':\n",
    "        test_part['search_term'].iloc[i]='[MASK]'\n",
    "        test_InputExamples.iloc[3].text_a=test_InputExamples.iloc[3].text_a.replace('presentation','[MASK]')\n",
    "    binar3.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "binar4=[]\n",
    "for i in range (len(pred_InputExamples)):\n",
    "    c=[]\n",
    "    for j in tokenizer.tokenize(pred_InputExamples.iloc[i].text_a):\n",
    "        search_1=pred_part['search_term'].iloc[i]    \n",
    "        if search_1.lower() in search_dict.keys():\n",
    "            search_2=search_dict[search_1.lower()]\n",
    "        else:\n",
    "            search_2=list(search_dict.keys())[list(search_dict.values()).index(search_1.lower())]\n",
    "        if j==search_1.lower() or j==search_2:\n",
    "            c.append(1)\n",
    "        else:\n",
    "            c.append(0)\n",
    "    if search_1=='presentation':\n",
    "        pred_part['search_term'].iloc[i]='[MASK]'\n",
    "        pred_InputExamples.iloc[3].text_a=pred_InputExamples.iloc[3].text_a.replace('presentation','[MASK]')\n",
    "    binar4.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in binar:\n",
    "     while len(i)<128:\n",
    "        i.append(0)\n",
    "binar=np.array(binar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in binar2:\n",
    "     while len(i)<128:\n",
    "        i.append(0)\n",
    "binar2=np.array(binar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in binar3:\n",
    "     while len(i)<128:\n",
    "        i.append(0)\n",
    "binar3=np.array(binar3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binar5=[]\n",
    "for i in binar4:\n",
    "    if len(i)>128:\n",
    "        i=i[:128]  \n",
    "        binar5.append(i)\n",
    "    else:\n",
    "        while len(i)<128:\n",
    "            i.append(0)\n",
    "        binar5.append(i)\n",
    "binar5=np.array(binar5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtvrR5eusZPO"
   },
   "source": [
    "We will now format out text in to input features which the BERT model expects. We will also set a sequence length which will be the length of the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WlCnyM6J51qC"
   },
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LL5W8gEGRTAf",
    "outputId": "3a2523d9-3df8-4142-89f7-c92bf34df8b6"
   },
   "outputs": [],
   "source": [
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_features = bert.run_classifier.convert_examples_to_features(pred_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_features)):\n",
    "    train_features[i].binary_seq=list(binar[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(val_features)):\n",
    "    val_features[i].binary_seq=list(binar2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_features)):\n",
    "    test_features[i].binary_seq=list(binar3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred_features)):\n",
    "    pred_features[i].binary_seq=list(binar5[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "WZEmm8KEUX3F",
    "outputId": "c32d219b-3297-4b26-c799-1cd9cc08fe06"
   },
   "outputs": [],
   "source": [
    "#Example on first observation in the training set\n",
    "print(\"### Text : \\n\", train_InputExamples.iloc[0].text_a)\n",
    "print(\"-\"*30)\n",
    "print(\"### Input IDs : \", train_features[0].input_ids)\n",
    "print(\"-\"*30)\n",
    "print(\"### Input Masks : \", train_features[0].input_mask)\n",
    "print(\"-\"*30)\n",
    "print(\"### Segment IDs : \", train_features[0].segment_ids)\n",
    "print(\"-\"*30)\n",
    "print(\"### binary_seq : \", train_features[0].binary_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ccp5trMwRtmr"
   },
   "source": [
    "## Creating a Multi-Class Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6o2a5ZIvRcJq"
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels,binary_seq):\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\", # bert_inputs records tokens\n",
    "      as_dict=True) # bert_inputs is a dict\n",
    "\n",
    "  # !!! Use \"pooled_output\" for classification tasks on an entire sentence. ---> adopted for classification\n",
    "  # !!! Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "  word_layer = bert_outputs[\"sequence_output\"]\n",
    "\n",
    "  binary_seq=tf.expand_dims(binary_seq, 2)\n",
    "  word_layer = tf.multiply(word_layer, binary_seq)\n",
    "  word_layer=tf.reduce_sum(word_layer,axis=1)\n",
    "  #output_layer=tf.concat([output_layer,word_layer],axis=1)\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "  middle_size=[32,64,128,256,512]\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  \"\"\"\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "    word_layer = tf.nn.dropout(word_layer, keep_prob=0.9)\n",
    "    #print(output_layer.shape)\n",
    "    #print(word_layer.shape)\n",
    "    output_layer = tf.layers.dense(output_layer, middle_size[4], activation=tf.nn.relu)#add part\n",
    "    word_layer = tf.layers.dense(word_layer, middle_size[4], activation=tf.nn.relu)\n",
    "    #print(output_layer.shape)\n",
    "    #print(word_layer.shape)\n",
    "    logits=tf.concat([output_layer,word_layer],axis=1)\n",
    "    #print(logits.shape)\n",
    "    logits_out=logits\n",
    "    logits = tf.layers.dense(logits, num_labels)#add part\n",
    "    #print(logits.shape)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "    \n",
    "\n",
    "   \n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "    #print(\"one_hot_labels:\",one_hot_labels.shape)\n",
    "    \n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    #print(\"predicted_labels:\",predicted_labels.shape)\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs,logits_out)\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FnH-AnOQ9KKW"
   },
   "outputs": [],
   "source": [
    "# A function that adapts our model to work for training, evaluation, and prediction.\n",
    "\n",
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "    binary_seq = features[\"binary_seq\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels,binary_seq)\n",
    "      \n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        #auc = tf.metrics.auc(label_ids, predicted_labels)\n",
    "        precision=tf.metrics.precision(label_ids, predicted_labels)\n",
    "        recall=tf.metrics.recall(label_ids, predicted_labels)\n",
    "        #specificity_at_sensitivity=tf.metrics.specificity_at_sensitivity(label_ids, predicted_labels)\n",
    "        #CategoricalCrossentropy=tf.keras.metrics.CategoricalCrossentropy(label_ids, predicted_labels)\n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            #\"auc\":auc,\n",
    "            \"precision\":precision,\n",
    "            \"recall\":recall,\n",
    "            #\"specificity_at_sensitivity\":specificity_at_sensitivity,\n",
    "            #\"CategoricalCrossentropy\":CategoricalCrossentropy,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg\n",
    "            }\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "\n",
    "    else:\n",
    "      \n",
    "      (predicted_labels, log_probs,logits_out) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels,binary_seq)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels,\n",
    "          'logits_out': logits_out\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjwJ4bTeWXD8"
   },
   "outputs": [],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 4.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "q_WebpS1X97v",
    "outputId": "053847bc-68e4-4ae5-e2ed-ab19bebcd77b"
   },
   "outputs": [],
   "source": [
    "#Initializing the model and the estimator\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE}) #,\"max_lenth\":MAX_SEQ_LENGTH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
    "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "  all_input_ids = []\n",
    "  all_input_mask = []\n",
    "  all_segment_ids = []\n",
    "  all_label_ids = []\n",
    "  all_binary_seq = []\n",
    "  for feature in features:\n",
    "    \n",
    "    all_input_ids.append(feature.input_ids)\n",
    "    all_input_mask.append(feature.input_mask)\n",
    "    all_segment_ids.append(feature.segment_ids)\n",
    "    all_label_ids.append(feature.label_id)\n",
    "    all_binary_seq.append(feature.binary_seq)\n",
    "  def input_fn(params):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "    batch_size = params[\"batch_size\"]\n",
    "\n",
    "    num_examples = len(features)\n",
    "\n",
    "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
    "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
    "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
    "    d = tf.data.Dataset.from_tensor_slices({\n",
    "        \"input_ids\":\n",
    "            tf.constant(\n",
    "                all_input_ids, shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"input_mask\":\n",
    "            tf.constant(\n",
    "                all_input_mask,\n",
    "                shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"segment_ids\":\n",
    "            tf.constant(\n",
    "                all_segment_ids,\n",
    "                shape=[num_examples, seq_length],\n",
    "                dtype=tf.int32),\n",
    "        \"label_ids\":\n",
    "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "        \"binary_seq\":\n",
    "            tf.constant(\n",
    "                all_binary_seq, \n",
    "                shape=[num_examples, seq_length],\n",
    "                dtype=tf.float32)\n",
    "    })\n",
    "\n",
    "    if is_training:\n",
    "      d = d.repeat()\n",
    "      d = d.shuffle(buffer_size=100)\n",
    "\n",
    "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "    return d\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOO3RfG1DYLo"
   },
   "source": [
    "we will now create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Pv2bAlOX_-K"
   },
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_fn = input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_fn = input_fn_builder(\n",
    "    features=pred_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vrumsg9uygH"
   },
   "source": [
    "## Training & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nucD4gluYJmK",
    "outputId": "72018f0b-49b4-4b9b-c2b4-8ef98e785225",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)#\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "PPVEXhNjYXC-",
    "outputId": "c2cbdd33-5825-49f0-f90e-180e6bd14f87"
   },
   "outputs": [],
   "source": [
    "#Evaluating the model with Validation set\n",
    "#estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6f9Rlhrupt6"
   },
   "source": [
    "## Predicting For Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A method to get predictions\n",
    "def getPrediction2(in_sentences,pred_input_fn):\n",
    "  # Transforming the test data into BERT accepted form\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 1) for x in in_sentences] \n",
    "  \n",
    "  # Creating input features for Test data\n",
    "  predictions=estimator.predict(input_fn=pred_input_fn)\n",
    "  return [(sentence, prediction['labels'],prediction['logits_out']) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = list(pred['clean tweet'])\n",
    "predictions = getPrediction2(pred_sentences,pred_input_fn)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relate=[]\n",
    "for i in range(len(predictions)):\n",
    "    relate.append(predictions[i][1])\n",
    "relate=np.array(relate)\n",
    "relate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(stock+\"_stock_sum/\"+\"relate_\"+stock+\"_\"+year+\".npy\", relate)\n",
    "print(stock+\"_stock_sum/\"+\"relate_\"+stock+\"_\"+year+\".npy\"+\" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentences = list(test['clean tweet'])\n",
    "predictions = getPrediction2(pred_sentences,test_input_fn)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_labels = []\n",
    "texts = []\n",
    "for i in range(len(predictions)):\n",
    "  enc_labels.append(label_list[predictions[i][1]]) # [0, 1] \n",
    "  texts.append(predictions[i][0].replace('\\n', ' '))\n",
    "\n",
    "import numpy as np\n",
    "table = pd.DataFrame({'Text':texts, 'Label':enc_labels, 'True':test['target']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table['True'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(table['True'], table['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qi5MqgDRhZno"
   },
   "source": [
    "# Reference:\n",
    "Most of the code has been taken from the following resource:\n",
    "\n",
    "* https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb\n",
    "* https://analyticsindiamag.com/step-by-step-guide-to-implement-multi-class-classification-with-bert-tensorflow/\n",
    "* https://github.com/AmalVijayan/BERT-For-Multi-Class-Classification\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Predicting_News_Category_with_BERT_In_Tensorflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
